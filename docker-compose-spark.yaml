version: '3'

services:
  # Spark with 3 workers
  spark:
    # image: bitnami/spark:3.1.2
    build:
        context: .
        dockerfile: Dockerfile-spark
    user: root # Run container as root container: https://docs.bitnami.com/tutorials/work-with-non-root-containers/
    hostname: spark
    environment:
        - SPARK_MODE=master
        - SPARK_RPC_AUTHENTICATION_ENABLED=no
        - SPARK_RPC_ENCRYPTION_ENABLED=no
        - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
        - SPARK_SSL_ENABLED=no
    volumes:
        - ${AIRFLOW_PROJ_DIR:-.}/spark/app:/usr/local/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
        - ${AIRFLOW_PROJ_DIR:-.}/spark/resources:/usr/local/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)
    ports:
        - "8181:8080"
        - "7077:7077"

  spark-worker-1:
      # image: bitnami/spark:3.1.2
      build:
          context: .
          dockerfile: Dockerfile-spark
      user: root
      environment:
          - SPARK_MODE=worker
          - SPARK_MASTER_URL=spark://spark:7077
          - SPARK_WORKER_MEMORY=1G
          - SPARK_WORKER_CORES=1
          - SPARK_RPC_AUTHENTICATION_ENABLED=no
          - SPARK_RPC_ENCRYPTION_ENABLED=no
          - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
          - SPARK_SSL_ENABLED=no
      volumes:
          - ${AIRFLOW_PROJ_DIR:-.}/spark/app:/usr/local/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
          - ${AIRFLOW_PROJ_DIR:-.}/spark/resources:/usr/local/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)

